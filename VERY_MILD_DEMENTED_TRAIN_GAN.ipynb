{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq0EUW1gPwv6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xbKEpV5NQI5u",
        "outputId": "61a3ce20-f6fd-49d4-be83-438d783575a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To generate GIFs\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzpuuk04QKYQ",
        "outputId": "b83544e0-8cc2-4957-c4c7-fb8c69227172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-8qn2o676\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-8qn2o676\n",
            "  Resolved https://github.com/tensorflow/docs to commit badea29fa47ed6595244641bfee5a3d6717701f4\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (2.11.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.19.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.1.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.3.3)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (5.10.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (2.6.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (3.11.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=184468 sha256=d264266a9f5e0e9cd6a2275b1776a8bb4e911ff30959bcddf8c7de98b534d3a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sfraxflq/wheels/3b/ee/a2/ab4d36a9a4af495bcb936f3e849d4b497b65fa40548a68d6c3\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: tensorflow-docs\n",
            "Successfully installed tensorflow-docs-0.0.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import keras.utils as image\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "hFaCaFRqQLzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBDJDyUaQNu2",
        "outputId": "1e1233ce-5de2-4d23-c0cd-82186cd52295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATE_RES = 3 # Generation resolution factor\n",
        "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
        "GENERATE_SQUARE = 28\n",
        "IMAGE_CHANNELS = 1\n",
        "\n",
        "# Preview image\n",
        "PREVIEW_ROWS = 4\n",
        "PREVIEW_COLS = 7\n",
        "PREVIEW_MARGIN = 16\n",
        "\n",
        "# Size vector to generate images from\n",
        "SEED_SIZE = 100\n",
        "\n",
        "# Configuration\n",
        "DATA_PATH = '/content/drive/MyDrive/archive (1)/Alzheimer_s Dataset/train/VeryMildDemented'\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 60000\n",
        "\n",
        "print(f\"Will generate {GENERATE_SQUARE}px square images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuDhHozKQPuf",
        "outputId": "55fa5511-c249-437c-e534-85164c5a36d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will generate 28px square images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "faces_path = os.path.join(DATA_PATH)\n",
        "for filename in tqdm(os.listdir(faces_path)):\n",
        "    path = os.path.join(faces_path,filename)\n",
        "    image = Image.open(path).resize((GENERATE_SQUARE,GENERATE_SQUARE),Image.ANTIALIAS)\n",
        "    training_data.append(np.asarray(image))\n",
        "training_data = np.reshape(training_data,(-1,GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS))\n",
        "training_data = training_data.astype(np.float32)\n",
        "training_data = training_data / 127.5 - 1.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0ObwfmqQVSV",
        "outputId": "9102d9aa-f7d3-4157-83aa-3e1ba4f4865d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1792/1792 [00:37<00:00, 48.33it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "S8vBU9X1QZ29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "89o7ynksQcSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "DI2dMHvZQqm0",
        "outputId": "c660d3fd-2de7-483d-c03f-54a3deddd2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f35ef6aa970>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "iK451sgoQsf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0hVxURdQubm",
        "outputId": "52f3362d-5f33-483b-fbc7-72bfb05479da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.00124842]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "kZg0F7WmQy_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "1TG8F-SVQ1EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "UV5P3e20Q2qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "YSHCk9MWQ7n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "metadata": {
        "id": "q0SRLxnSQ9aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "metadata": {
        "id": "eFY94PSmQ_Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "p4zCsJqbRAsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "metadata": {
        "id": "qzZTFFFMRCoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(5, 5))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.savefig('/content/drive/MyDrive/archive (1)/Alzheimer_s Dataset/GAN/train/VeryMildDemented/image_at_epoch_{:04d}-{}.png'.format(epoch,i), cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "f0XMJ9TaREhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "XRFyhzEpRP0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_TiaKlqRR8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}